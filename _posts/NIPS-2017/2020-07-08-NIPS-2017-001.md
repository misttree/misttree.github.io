---
layout: post
title: "Attention Is All You Need"
date: 2020-07-09 09:00:00 +0800 
categories: NIPS-2017
tags: NIPS-2017

---
* content
{:toc}
---

<!-- more -->

# Conference： NIPS-2017

## Attention Is All You Need

目前针对于序列转换的模型大多都是复杂的循环模型或是卷积式的神经网络模型，并且使用Encoder-Decoder结构进行处理，而目前表现最好的模型则是使用结合了注意力机制的Encoder-Decoder模型来进行处理，本文提出了一个全新的网络结构：Transformer结构，完全的基于注意力机制来进行构建，摒弃了之前所具有的循环递归，卷积结构。在两个机器翻译领域的数据集上的训练展现了本文的模型的效果。并且本文提出的模型还能够在实验中尽可能地并行化处理，来节省训练所需要的时间。

本文在WMT 2014 English-to-German数据集与WMT 2014 English-to-French数据集上进行训练，并且达到了state-of-the-art的效果，并且我们还将模型成功应用至英语句法分析中，得到了较好的效果。