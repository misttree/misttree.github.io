---
layout: post
title: "MSMO Multimodal Summarization with Multimodal Output"
date: 2020-06-19 09:00:00 +0800 
categories: EMNLP-2018
tags: EMNLP-2018

---
* content
{:toc}
---

<!-- more -->

# MSMO: Multimodal Summarization with Multimodal Output

文章地址：[文章链接](http://www.nlpr.ia.ac.cn/cip/ZongPublications/2018/2018-JunnanZhu-emnlp.pdf)

受多模态数据集的迅速增长，针对于多模态形式的摘要系统的研究也逐渐受到关注。然而目前的主要摘要研究都是针对于文本形式的摘要内容，本文通过实验证明，针对于多个模态下的摘要内容输出能够更好的提升用户的满意度。

于是，本文提出了一个新的任务，基于多模态输出形式下的摘要系统（MSMO: multimodal summarization with multimodal output）.首先收集了一个大规模的多模态摘要系统数据集，来进行研究使用。之后提出了一个多模态注意力模型，完成对于文本摘要内容的生成与图片的选择工作，最后为了评估实验结果，本文提出了一种新式的多模态评估方式，其中，即考虑了针对于单个模态的信息提取的完整性，也考虑了多个模态之间信息的相关性，并最终进行实验证明了评估方式的高效性。

---

## Main Contributions

本文的主要工作内容可以分为以下几个部分：

1. 我们提出了一个新式的多模态摘要任务，以包含有多个图片的新闻作为输入，并最终输出一个带有图片的摘要内容，并构建了一个大规模的数据集为模型(MSMO)使用
2. 我们提出了一个抽象生成式的多模态摘要系统模型，来联合生成摘要内容与最相关的图片信息
3. 我们提出了一个多模态的自动评估方式，其中主要考虑三个方面：文本的主体性，图片的主体性，以及文本与图片之间的相关性

---

## 模型总结

模型结构可见下图：

![Model](https://s1.ax1x.com/2020/06/19/NK1Zbd.png)

模型主要包含有以下4个部分：文本编码器，图片编码器，多模态注意力层，摘要解码器。文本编码器使用一个单向的LSTM来对于文本进行编码，我们的图片编码器使用在ImageNet上已经预训练好的VGG19模型来对于图片的全局特征。而多模态注意力层的引入是为了在解码过程中，融合文本性与视觉性的信息。我们的摘要解码器是一个双向的LSTM，通过利用来自两个模态的信息完成对于文本的摘要生成工作，并根据视觉覆盖向量选择最相关的图片。我们的文本编码器与摘要解码器是基于指针生成网络进行构建的，

---

### 指针生成网络

See et al. (2017)提出指针生成网络，它能够完成从源文本中提取单词的工作，也能够完成从一个混合的词汇集合中生成单词的任务，并在CNN/Daily Mail数据集上取得了最好的表现。他们的模型主要包括一个编码器（一个简单的单向LSTM）以及一个注意力机制的解码器（一个双向的LSTM）。其中编码器会将文章内容编码成为一系列的隐藏状态$$h_i$$,并且在解码的过程中，解码器会受到之前的单词的编码信息，并达到一个新的状态$$s_t$$。其中上下文向量$$c_t$$是通过注意力机制来进行计算的，具体可以参考公式1，2。

为了减少关于重复性的问题，See et al. (2017)提出了代表之前的注意力分布的集合的覆盖向量$$cov_t=\sum_{t=0}^{t-1}α^{t}$$。而这个覆盖向量也是作为一个额外的输入加入至注意力向量中，并且还被用于计算覆盖损失。接下来注意力分布，具体可以参考公式1，2。

$$e_i^t=v^Ttanh(W_hh_i+W_ss_t+W_ccov^t)$$

$$α^t=softmax(e^t)$$

$$c_t=∑_iα_i^th_ii$$

该模型重要的部分为针对于生成概率的计算$$p_g$$，它代表了从一个词汇分布中生成一个单词的概率$$p_v$$，并且$$(1-p_g)$$代表了通过从注意力分布中采样而从源文本中拷贝单词的概率。$$p_g$$受$$c_t$$，$$s_t$$决定，以及解码器的输入$$x_t$$，具体会下面中进行描述。扩展词汇的最终概率分布表示该词汇与源中所有单词的并集，计算方法如下所示。最后，时间步长t的损失是目标单词$$w^∗_t$$的负对数似然概率和覆盖度损失的总和:

$$p_g=σ(W_h*c_t+W_s*s_t+W_xx_t)$$

$$p_w=p_gp_v(w)+(1-p_g)∑_{w_i=w}α_i^t$$

$$L_t=-log(p_{w^*_t})+∑_imin(α_i^t,cov_i^t)$$

---

### 多模态注意力模型

我们将视觉信息纳入指针生成器网络，并提出了一个新的多模态注意模型。如上图所示，我们的模型和指针生成器网络有三个主要区别:

1. 我们有一个额外的图像编码器和相应的视觉注意层
2. 为了实现文本信息和视觉信息的融合，我们引入了多模态注意机制
3. 我们增加了视觉覆盖，既可以缓解视觉重复，又可以测量图像的显著性

---

#### 图片编码器

我们使用VGG19提取所有图像的全局和局部特征向量。全局特征g是pre-softmax全连接层fc7的4096维激活。局部特征l为最后一个池化层(pool5)的7×7×512个特征图。我们将局部特征平化为矩阵A,其中矩阵A的每一维对应于图像的一个部分。

---

#### 视觉注意力机制

在译码过程中，注意机制用于学习集中于输入文本的不同部分。注意机制也可以应用于其他模态，比如图像，它们可以学习关注图像的突出部分。我们探索使用图像的视觉注意学习文本-图像对齐。具体来说，我们延伸了注意力机制到视觉注意机制，参与视觉信号。我们的视觉注意机制有三种变体:

1. 对全局特征的注意(ATG)
2. 对局部特征的注意(ATL)
3. 对局部特征的分层视觉注意(HAN)

我们以ATG的计算为例。为了考虑尺寸为M的图像集合的突出部分，我们将全局特征集g平化为一个矩阵g0除了计算文本上下文向量之外，我们也得到了一个视觉上下文向量。我们首先将图像特征投影到与文本上下文向量相同的维度中。视觉注意的计算方法如下:

![pic](https://s1.ax1x.com/2020/06/19/NKRNjS.jpg)

与ATL相似，我们将局部特征集合A平化为矩阵A0, 计算放式在ATL和ATG中是一样的。与HAN模型略有不同的是，该模型首先对49个图像patch进行处理，得到一个中间的视觉语境向量来表示图像，然后对中间的视觉语境向量进行处理，得到视觉语境向量。

---

#### 多模态注意力机制

为了融合文本和视觉上下文信息，我们添加了多模态注意层如图2所示。注意分布计算如下:

![pic](https://s1.ax1x.com/2020/06/19/NKRgjU.jpg)

其中，$$t_{txt}$$为文本上下文向量的注意权重，$$t_{img}$$为视觉上下文向量的注意权重。

---

#### 视觉覆盖率

除了计算文本覆盖向量外，我们还得到了视觉覆盖向量covimg t，它是视觉注意力分布的总和。为了帮助减少对多模式信息的重复关注，我们在损失函数中加入了文本覆盖损失和视觉覆盖损失。最终损失函数为

$$L_t=-log(p_{w_t^*})+∑_imin(α_i^t,cov_i^t)+∑_jmin(α_j^t,cov_{img,j}^t)$$

注意机制可以集中在文本或图像的突出部分。同时，覆盖机制对历史上所有的关注分布进行了总结。因此，我们将覆盖度矢量作为被关注源的全球显著性度量。然后利用最后一个解码时间步长的视觉覆盖向量来选择最相关的图像。具体来说，我们选择覆盖率分数最大的图像。对于局部特征的分层视觉注意力机制的处理过程略有不同。一幅图像对应49个patch，将这些patch的覆盖度评分相加，得到图像的显著性评分如下:

$$S_j = ∑_{pathc}cov_{patch,j}^{t*}$$

其中$$S_j$$表示第j个图像的显著性,$$cov_t$$表示每个对应图像patch在最后一个解码时间步长t*中的覆盖率，对于HAN，我们引入一个额外的图像patch注意的覆盖度向量，计算其覆盖度损失如下:

$$L_t=-log(p_{w_t^*})+∑_kmin(α_k^t,cov_{patch,k}^t)+∑_imin(α_i^t,cov_i^t)+∑_jmin(α_j^t,cov_{img,j}^t)$$

---

### 多模态自动评估方式

为了评估生成的多模态摘要的质量，我们提出MMAE(Multimodal Automatic Evaluation)方法,主要关注三个部分：文本的显著性，图片的显著性，图片与文本之间的相关性，针对于摘要文本的内容，我们使用ROUGE模型进行评估处理，针对于图片的显著性，我们定义图片精确度如下公式

$$IP = \frac{|{ref_{img}}∩{rec_{rmg}}|}{|{rec_{img}}|}$$

针对于图片文本相关性的评估考虑使用视觉语义编码模型进行处理，通过当前最优的VSE0模型，并进行一定调整，将图片特征与文本特征建模至同一个语义特征空间，并使用最大间隔损失进行训练

---

## 模型评估

### 模型的优点

模型的想法比较新，是针对于多模态摘要系统的一个重要问题的评估方式

### 模型的缺点

### 下一步研究
